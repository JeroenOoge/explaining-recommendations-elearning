{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import MaxNLocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pre = pd.read_csv('../Datasets/data/pre_study_questionnaire_updated.csv', sep=\",\")\n",
    "df = pd.read_csv('../Datasets/data/post_study_questionnaire_updated.csv', sep=\",\")\n",
    "rg_df = pd.read_csv('../Datasets/data/field_data_field_research_group_updated.csv', sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg_df = rg_df.drop(['entity_type', 'bundle', 'deleted', 'revision_id', 'language', 'delta'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=['UID']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Serienummer']>7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.merge(df,rg_df,how='inner', left_on='UID',right_on='entity_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>In welk leerjaar zit je?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1846</td>\n",
       "      <td>Anders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1847</td>\n",
       "      <td>Anders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1854</td>\n",
       "      <td>Anders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1864</td>\n",
       "      <td>Anders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1865</td>\n",
       "      <td>Anders</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    UID In welk leerjaar zit je?\n",
       "0  1846                   Anders\n",
       "1  1847                   Anders\n",
       "2  1854                   Anders\n",
       "3  1864                   Anders\n",
       "4  1865                   Anders"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grade_df = df_pre[['UID', 'In welk leerjaar zit je?']]\n",
    "grade_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.merge(result_df,grade_df,how='inner',left_on='UID',right_on='UID')\n",
    "result_df = result_df.drop_duplicates(subset=['UID']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = result_df[result_df['In welk leerjaar zit je?']!=\" Anders\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n",
      "12\n",
      "12\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "print(len(result_df))\n",
    "print(len(result_df[result_df[\"field_research_group_value\"]==0]))\n",
    "print(len(result_df[result_df[\"field_research_group_value\"]==1]))\n",
    "print(len(result_df[result_df[\"field_research_group_value\"]==2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df = result_df[result_df[\"field_research_group_value\"]==0]\n",
    "placebo_df = result_df[result_df[\"field_research_group_value\"]==1]\n",
    "nothing_df = result_df[result_df[\"field_research_group_value\"]==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = '1. Wiski is zoals een expert (bv. een leerkracht) in wiskunde-oefeningen aanraden.\\t'\n",
    "q2 = '2. Wiski heeft de expertise (kennis) om mijn wiskundeniveau te kunnen inschatten.'\n",
    "q3 = '3. Wiski kan mijn wiskundeniveau inschatten.'\n",
    "q4 = '4. Wiski begrijpt de moeilijkheidsgraad van wiskunde-oefeningen goed.'\n",
    "q5 = '5. Wiski houdt rekening met mijn wiskundeniveau om oefeningen aan te raden.'\n",
    "q6 = '6. Wiski zet op de eerste plaats dat ik vorderingen maak in wiskunde.'\n",
    "q7 = '7. Wanneer Wiski oefeningen aanraadt, doet Wiski dat zodat ik vorderingen maak in wiskunde.'\n",
    "q8 = '8. Wiski wilt mijn wiskundeniveau goed inschatten.'\n",
    "q9 = '9. Wiski raadt oefeningen op een zo correct mogelijke manier aan.'\n",
    "q10 = '10. Wiski is eerlijk.'\n",
    "q11 = '11. Wiski maakt oprechte aanbevelingen.'\n",
    "q12 = '12. Ik vertrouw Wiski om mij wiskunde-oefeningen aan te raden.'\n",
    "q13 = '13. Als ik nog eens online wiskunde-oefeningen maak, dan kies ik voor Wiski.'\n",
    "q14 = '14. Als ik nog eens wiskunde-oefeningen aangeraden wil krijgen, dan kies ik voor Wiski.'\n",
    "q15 = '15. Ik vind dat Wiski genoeg uitleg geeft over waarom een oefening aangeraden is.'\n",
    "q16 = '16. Wanneer ik Wiski gebruik, wil ik GEEN uitleg over waarom een oefening wordt aangeraden.'\n",
    "q17 = '17. Ik vind uitleg krijgen over waarom een oefening wordt aangeraden belangrijker dan waarom een film wordt aangeraden.'\n",
    "q18 = '18. Ik ben NIET blij met het niveau van de oefeningen die Wiski aanraadde.'\n",
    "q19 = '19. In het algemeen vind ik het belangrijk om uitleg te krijgen wanneer iets (oefening/film/product/...) wordt aangeraden.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' Eens': 9, ' Eerder eens': 2, ' Eerder oneens': 1}\n"
     ]
    }
   ],
   "source": [
    "# real explanations \n",
    "group_df = real_df\n",
    "rq1 = group_df[q1].value_counts().to_dict()\n",
    "rq2 = group_df[q2].value_counts().to_dict()\n",
    "rq3 = group_df[q3].value_counts().to_dict()\n",
    "rq4 = group_df[q4].value_counts().to_dict()\n",
    "rq5 = group_df[q5].value_counts().to_dict()\n",
    "rq6 = group_df[q6].value_counts().to_dict()\n",
    "rq7 = group_df[q7].value_counts().to_dict()\n",
    "rq8 = group_df[q8].value_counts().to_dict()\n",
    "rq9 = group_df[q9].value_counts().to_dict()\n",
    "rq10 = group_df[q10].value_counts().to_dict()\n",
    "rq11 = group_df[q11].value_counts().to_dict()\n",
    "rq12 = group_df[q12].value_counts().to_dict()\n",
    "rq13 = group_df[q13].value_counts().to_dict()\n",
    "rq14 = group_df[q14].value_counts().to_dict()\n",
    "rq15 = group_df[q15].value_counts().to_dict()\n",
    "rq16 = group_df[q16].value_counts().to_dict()\n",
    "rq17 = group_df[q17].value_counts().to_dict()\n",
    "rq18 = group_df[q18].value_counts().to_dict()\n",
    "rq19 = group_df[q19].value_counts().to_dict()\n",
    "print(rq1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' Eens': 4, ' Eerder eens': 4, ' Neutraal': 1, ' Oneens': 1, ' Helemaal eens': 1, ' Helemaal oneens': 1}\n"
     ]
    }
   ],
   "source": [
    "# placebo explanations \n",
    "group_df = placebo_df\n",
    "pq1 = group_df[q1].value_counts().to_dict()\n",
    "pq2 = group_df[q2].value_counts().to_dict()\n",
    "pq3 = group_df[q3].value_counts().to_dict()\n",
    "pq4 = group_df[q4].value_counts().to_dict()\n",
    "pq5 = group_df[q5].value_counts().to_dict()\n",
    "pq6 = group_df[q6].value_counts().to_dict()\n",
    "pq7 = group_df[q7].value_counts().to_dict()\n",
    "pq8 = group_df[q8].value_counts().to_dict()\n",
    "pq9 = group_df[q9].value_counts().to_dict()\n",
    "pq10 = group_df[q10].value_counts().to_dict()\n",
    "pq11 = group_df[q11].value_counts().to_dict()\n",
    "pq12 = group_df[q12].value_counts().to_dict()\n",
    "pq13 = group_df[q13].value_counts().to_dict()\n",
    "pq14 = group_df[q14].value_counts().to_dict()\n",
    "pq15 = group_df[q15].value_counts().to_dict()\n",
    "pq16 = group_df[q16].value_counts().to_dict()\n",
    "pq17 = group_df[q17].value_counts().to_dict()\n",
    "pq18 = group_df[q18].value_counts().to_dict()\n",
    "pq19 = group_df[q19].value_counts().to_dict()\n",
    "print(pq1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' Eens': 5, ' Eerder eens': 5, ' Neutraal': 3}\n"
     ]
    }
   ],
   "source": [
    "# no explanations \n",
    "group_df = nothing_df\n",
    "nq1 = group_df[q1].value_counts().to_dict()\n",
    "nq2 = group_df[q2].value_counts().to_dict()\n",
    "nq3 = group_df[q3].value_counts().to_dict()\n",
    "nq4 = group_df[q4].value_counts().to_dict()\n",
    "nq5 = group_df[q5].value_counts().to_dict()\n",
    "nq6 = group_df[q6].value_counts().to_dict()\n",
    "nq7 = group_df[q7].value_counts().to_dict()\n",
    "nq8 = group_df[q8].value_counts().to_dict()\n",
    "nq9 = group_df[q9].value_counts().to_dict()\n",
    "nq10 = group_df[q10].value_counts().to_dict()\n",
    "nq11 = group_df[q11].value_counts().to_dict()\n",
    "nq12 = group_df[q12].value_counts().to_dict()\n",
    "nq13 = group_df[q13].value_counts().to_dict()\n",
    "nq14 = group_df[q14].value_counts().to_dict()\n",
    "nq15 = group_df[q15].value_counts().to_dict()\n",
    "nq16 = group_df[q16].value_counts().to_dict()\n",
    "nq17 = group_df[q17].value_counts().to_dict()\n",
    "nq18 = group_df[q18].value_counts().to_dict()\n",
    "nq19 = group_df[q19].value_counts().to_dict()\n",
    "print(nq1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_likert_to_int(d):\n",
    "    converted = dict()\n",
    "    for pair in d.items():\n",
    "        key = pair[0].strip()\n",
    "        value = pair[1]\n",
    "        if key == \"Helemaal oneens\":\n",
    "            converted[1] = int(value)\n",
    "        elif key == \"Oneens\":\n",
    "            converted[2] = int(value)\n",
    "        elif key == \"Eerder oneens\":\n",
    "            converted[3] = int(value)\n",
    "        elif key == \"Neutraal\":\n",
    "            converted[4] = int(value)\n",
    "        elif key == \"Eerder eens\":\n",
    "            converted[5] = int(value)\n",
    "        elif key == \"Eens\":\n",
    "            converted[6] = int(value)\n",
    "        elif key == \"Helemaal eens\":\n",
    "            converted[7] = int(value)\n",
    "        else:\n",
    "            print(key)\n",
    "    return converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{6: 9, 5: 2, 3: 1}\n"
     ]
    }
   ],
   "source": [
    "# real converted to values\n",
    "rqv1 = convert_likert_to_int(rq1)\n",
    "rqv2 = convert_likert_to_int(rq2)\n",
    "rqv3 = convert_likert_to_int(rq3)\n",
    "rqv4 = convert_likert_to_int(rq4)\n",
    "rqv5 = convert_likert_to_int(rq5)\n",
    "rqv6 = convert_likert_to_int(rq6)\n",
    "rqv7 = convert_likert_to_int(rq7)\n",
    "rqv8 = convert_likert_to_int(rq8)\n",
    "rqv9 = convert_likert_to_int(rq9)\n",
    "rqv10 = convert_likert_to_int(rq10)\n",
    "rqv11 = convert_likert_to_int(rq11)\n",
    "rqv12 = convert_likert_to_int(rq12)\n",
    "rqv13 = convert_likert_to_int(rq13)\n",
    "rqv14 = convert_likert_to_int(rq14)\n",
    "rqv15 = convert_likert_to_int(rq15)\n",
    "rqv16 = convert_likert_to_int(rq16)\n",
    "rqv17 = convert_likert_to_int(rq17)\n",
    "rqv18 = convert_likert_to_int(rq18)\n",
    "rqv19 = convert_likert_to_int(rq19)\n",
    "print(rqv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placebo converted to values\n",
    "pqv1 = convert_likert_to_int(pq1)\n",
    "pqv2 = convert_likert_to_int(pq2)\n",
    "pqv3 = convert_likert_to_int(pq3)\n",
    "pqv4 = convert_likert_to_int(pq4)\n",
    "pqv5 = convert_likert_to_int(pq5)\n",
    "pqv6 = convert_likert_to_int(pq6)\n",
    "pqv7 = convert_likert_to_int(pq7)\n",
    "pqv8 = convert_likert_to_int(pq8)\n",
    "pqv9 = convert_likert_to_int(pq9)\n",
    "pqv10 = convert_likert_to_int(pq10)\n",
    "pqv11 = convert_likert_to_int(pq11)\n",
    "pqv12 = convert_likert_to_int(pq12)\n",
    "pqv13 = convert_likert_to_int(pq13)\n",
    "pqv14 = convert_likert_to_int(pq14)\n",
    "pqv15 = convert_likert_to_int(pq15)\n",
    "pqv16 = convert_likert_to_int(pq16)\n",
    "pqv17 = convert_likert_to_int(pq17)\n",
    "pqv18 = convert_likert_to_int(pq18)\n",
    "pqv19 = convert_likert_to_int(pq19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nothing converted to values\n",
    "nqv1 = convert_likert_to_int(nq1)\n",
    "nqv2 = convert_likert_to_int(nq2)\n",
    "nqv3 = convert_likert_to_int(nq3)\n",
    "nqv4 = convert_likert_to_int(nq4)\n",
    "nqv5 = convert_likert_to_int(nq5)\n",
    "nqv6 = convert_likert_to_int(nq6)\n",
    "nqv7 = convert_likert_to_int(nq7)\n",
    "nqv8 = convert_likert_to_int(nq8)\n",
    "nqv9 = convert_likert_to_int(nq9)\n",
    "nqv10 = convert_likert_to_int(nq10)\n",
    "nqv11 = convert_likert_to_int(nq11)\n",
    "nqv12 = convert_likert_to_int(nq12)\n",
    "nqv13 = convert_likert_to_int(nq13)\n",
    "nqv14 = convert_likert_to_int(nq14)\n",
    "nqv15 = convert_likert_to_int(nq15)\n",
    "nqv16 = convert_likert_to_int(nq16)\n",
    "nqv17 = convert_likert_to_int(nq17)\n",
    "nqv18 = convert_likert_to_int(nq18)\n",
    "nqv19 = convert_likert_to_int(nq19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{6: 9, 5: 2, 3: 1}, {6: 6, 5: 3, 4: 1, 3: 1, 7: 1}, {6: 7, 7: 2, 5: 1, 4: 1, 2: 1}, {6: 7, 4: 2, 7: 2, 5: 1}, {7: 5, 6: 3, 5: 3, 3: 1}, {6: 8, 5: 2, 7: 2}, {6: 6, 5: 3, 4: 2, 7: 1}, {6: 6, 7: 6}, {6: 8, 5: 2, 7: 2}, {7: 6, 5: 4, 4: 1, 6: 1}, {7: 6, 6: 5, 4: 1}, {6: 5, 7: 4, 5: 2, 3: 1}, {6: 6, 5: 2, 4: 2, 7: 2}, {6: 8, 5: 2, 4: 1, 7: 1}, {7: 5, 4: 2, 5: 2, 3: 2, 6: 1}, {2: 4, 4: 2, 3: 2, 1: 2, 5: 1, 6: 1}, {4: 4, 5: 2, 2: 2, 7: 2, 3: 1, 1: 1}, {2: 5, 3: 3, 4: 2, 1: 1, 7: 1}, {6: 5, 4: 4, 5: 3}]\n"
     ]
    }
   ],
   "source": [
    "rqv = [rqv1,\n",
    "rqv2,\n",
    "rqv3,\n",
    "rqv4,\n",
    "rqv5,\n",
    "rqv6,\n",
    "rqv7,\n",
    "rqv8,\n",
    "rqv9,\n",
    "rqv10,\n",
    "rqv11,\n",
    "rqv12,\n",
    "rqv13,\n",
    "rqv14,\n",
    "rqv15,\n",
    "rqv16,\n",
    "rqv17,\n",
    "rqv18,\n",
    "rqv19]\n",
    "print(rqv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{6: 4, 5: 4, 4: 1, 2: 1, 7: 1, 1: 1}, {6: 4, 4: 3, 5: 2, 3: 2, 7: 1}, {6: 5, 4: 4, 5: 2, 3: 1}, {6: 5, 3: 3, 5: 2, 4: 1, 7: 1}, {6: 8, 5: 1, 3: 1, 4: 1, 7: 1}, {6: 4, 4: 3, 7: 3, 5: 2}, {6: 5, 5: 3, 7: 2, 4: 1, 2: 1}, {6: 8, 4: 2, 2: 1, 7: 1}, {6: 8, 4: 2, 3: 1, 7: 1}, {6: 6, 4: 2, 7: 2, 3: 1, 5: 1}, {6: 6, 4: 4, 3: 1, 7: 1}, {6: 6, 4: 2, 5: 1, 3: 1, 2: 1, 7: 1}, {6: 6, 5: 4, 4: 1, 2: 1}, {6: 7, 3: 2, 5: 1, 4: 1, 7: 1}, {5: 4, 3: 3, 6: 2, 4: 2, 2: 1}, {2: 5, 1: 3, 4: 2, 5: 2}, {6: 4, 5: 3, 4: 2, 3: 2, 2: 1}, {2: 5, 1: 4, 4: 3}, {4: 3, 5: 3, 6: 3, 3: 2, 7: 1}]\n"
     ]
    }
   ],
   "source": [
    "pqv = [pqv1,\n",
    "pqv2,\n",
    "pqv3,\n",
    "pqv4,\n",
    "pqv5,\n",
    "pqv6,\n",
    "pqv7,\n",
    "pqv8,\n",
    "pqv9,\n",
    "pqv10,\n",
    "pqv11,\n",
    "pqv12,\n",
    "pqv13,\n",
    "pqv14,\n",
    "pqv15,\n",
    "pqv16,\n",
    "pqv17,\n",
    "pqv18,\n",
    "pqv19]\n",
    "print(pqv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nqv = [nqv1,\n",
    "nqv2,\n",
    "nqv3,\n",
    "nqv4,\n",
    "nqv5,\n",
    "nqv6,\n",
    "nqv7,\n",
    "nqv8,\n",
    "nqv9,\n",
    "nqv10,\n",
    "nqv11,\n",
    "nqv12,\n",
    "nqv13,\n",
    "nqv14,\n",
    "nqv15,\n",
    "nqv16,\n",
    "nqv17,\n",
    "nqv18,\n",
    "nqv19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calclulate_values_per_question(list_of_dicts):\n",
    "    result = []\n",
    "    for dic in list_of_dicts:\n",
    "        to_add = 0\n",
    "        for pair in dic.items():\n",
    "            key = pair[0]\n",
    "            value = pair[1]\n",
    "            to_add += key * value\n",
    "        result.append(to_add)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_per_construct(lijst, num_students):\n",
    "    result = dict()\n",
    "    result[\"competence\"] = sum(lijst[0:5])/num_students\n",
    "    result[\"benevolence\"] = sum(lijst[5:8])/num_students\n",
    "    result[\"integrity\"] = sum(lijst[8:11])/num_students\n",
    "    result[\"explicit_trust\"] = lijst[11]/num_students\n",
    "    result[\"intention_to_return\"] = sum(lijst[12:14])/num_students\n",
    "    result[\"perceived_transparency\"] = lijst[14]/num_students\n",
    "    result[\"16\"] = lijst[15]/num_students\n",
    "    result[\"17\"] = lijst[16]/num_students  \n",
    "    result[\"18\"] = lijst[17]/num_students\n",
    "    result[\"19\"] = lijst[18]/num_students\n",
    "    return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[67, 65, 67, 69, 71, 72, 66, 78, 72, 72, 76, 71, 68, 69, 65, 35, 48, 35, 61]\n",
      "{'competence': 28.25, 'benevolence': 18.0, 'integrity': 18.333333333333332, 'explicit_trust': 5.916666666666667, 'intention_to_return': 11.416666666666666, 'perceived_transparency': 5.416666666666667, '16': 2.9166666666666665, '17': 4.0, '18': 2.9166666666666665, '19': 5.083333333333333}\n"
     ]
    }
   ],
   "source": [
    "real_values_per_question = calclulate_values_per_question(rqv)\n",
    "print(real_values_per_question)\n",
    "real_average_per_construct = calculate_average_per_construct(real_values_per_question, len(real_df))\n",
    "print(real_average_per_construct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58, 59, 59, 60, 67, 67, 65, 65, 66, 66, 62, 61, 62, 64, 51, 31, 55, 26, 58]\n",
      "{'competence': 25.25, 'benevolence': 16.416666666666668, 'integrity': 16.166666666666668, 'explicit_trust': 5.083333333333333, 'intention_to_return': 10.5, 'perceived_transparency': 4.25, '16': 2.5833333333333335, '17': 4.583333333333333, '18': 2.1666666666666665, '19': 4.833333333333333}\n"
     ]
    }
   ],
   "source": [
    "placebo_values_per_question = calclulate_values_per_question(pqv)\n",
    "print(placebo_values_per_question)\n",
    "placebo_average_per_construct = calculate_average_per_construct(placebo_values_per_question, len(placebo_df))\n",
    "print(placebo_average_per_construct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[67, 66, 66, 64, 72, 71, 67, 75, 73, 84, 75, 69, 68, 69, 44, 32, 54, 32, 72]\n",
      "{'competence': 25.76923076923077, 'benevolence': 16.384615384615383, 'integrity': 17.846153846153847, 'explicit_trust': 5.3076923076923075, 'intention_to_return': 10.538461538461538, 'perceived_transparency': 3.3846153846153846, '16': 2.4615384615384617, '17': 4.153846153846154, '18': 2.4615384615384617, '19': 5.538461538461538}\n"
     ]
    }
   ],
   "source": [
    "nothing_values_per_question = calclulate_values_per_question(nqv)\n",
    "print(nothing_values_per_question)\n",
    "nothing_average_per_construct = calculate_average_per_construct(nothing_values_per_question, len(nothing_df))\n",
    "print(nothing_average_per_construct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ik heb niet echt uitleg gezien. ',\n",
       "       'er wordt niet echt vermeldt waarom de oefening aangeraden wordt. (bv: omdat het hetzelfde/ moeilijker/makkelijk niveau heeft)',\n",
       "       'Misschien heb ik erover gekeken maar ik heb nog niet echt een uitleg hierover gezien.',\n",
       "       'Ik heb nog geen uitleg gezien maar misschien ben ik het gewoon overgeslagen',\n",
       "       'ik vind het heel handig dat er gemiddeld en moeilijk enz bij de oefeningen staan.',\n",
       "       'Ik heb dit precies gemist',\n",
       "       'Ik heb nog geen uitleg gezien, maar ik heb er ook nog geen nodig gehad.',\n",
       "       'Ik heb nergens gelezen waarom een oefening aan mij werd aangeraden. ',\n",
       "       'Als je een nieuwe oefening wilt maken is het handig dat je weet waarom deze oefening aangeraden wordt, dit doet de website goed.',\n",
       "       'Ik kreeg geen uitleg waarom het werd aangeraden',\n",
       "       'Ik heb geen uitleg gezien. Er stond gewoon dat het aangereden werd. ',\n",
       "       'Ja ik vind dat er genoeg uitleg is.',\n",
       "       \"Ik kan nergens echt vinden 'waarom' een oefening wordt aangeraden.\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nothing_df['Motiveer (verplicht) jouw antwoord op vraag 15.'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9, 10, 26, '04/26/2021 - 11:17', '04/26/2021 - 11:17',\n",
       "        '04/26/2021 - 11:17', 0, 1888,\n",
       "        'b318ab61-0287-4963-bb64-945bb531f0ac', ' Eerder eens',\n",
       "        ' Eerder eens', ' Eerder eens', ' Eens', ' Eerder eens', nan,\n",
       "        nan, ' Eerder eens', ' Neutraal', ' Eens', nan, nan,\n",
       "        ' Eerder eens', ' Eens', ' Eerder eens', nan, nan,\n",
       "        ' Eerder eens', nan, nan, ' Eerder eens', ' Eerder eens', nan,\n",
       "        nan, ' Eerder oneens', 'Ik heb niet echt uitleg gezien. ', nan,\n",
       "        ' Neutraal', ' Eerder oneens', ' Oneens', ' Neutraal',\n",
       "        'Ik zou graag de tussenstappen naar de oplossing erbij krijgen als je iets fout had.',\n",
       "        nan, 1888, 2, ' 4e middelbaar'],\n",
       "       [10, 11, 28, '04/26/2021 - 13:47', '04/26/2021 - 13:47',\n",
       "        '04/26/2021 - 13:47', 0, 1889,\n",
       "        '63f82d59-6853-4937-9204-f3e9b73e672b', ' Eerder eens',\n",
       "        ' Eerder eens', ' Eens', ' Eerder eens', ' Eens', nan, nan,\n",
       "        ' Eens', ' Eens', ' Eens', nan, nan, ' Eens', ' Eens', ' Eens',\n",
       "        nan, nan, ' Eens', nan, nan, ' Eerder eens', ' Eerder eens', nan,\n",
       "        nan, ' Neutraal',\n",
       "        'er wordt niet echt vermeldt waarom de oefening aangeraden wordt. (bv: omdat het hetzelfde/ moeilijker/makkelijk niveau heeft)',\n",
       "        nan, ' Neutraal', ' Eerder eens', ' Oneens', ' Neutraal',\n",
       "        'Het is een beetje onhandig dat de uitwerking van de oefeningen, die je fout had, niet gegeven wordt.',\n",
       "        nan, 1889, 2, ' 4e middelbaar'],\n",
       "       [12, 13, 34, '04/26/2021 - 18:48', '04/26/2021 - 18:48',\n",
       "        '04/26/2021 - 18:48', 0, 1893,\n",
       "        '78b9761a-e3ab-4b7f-bd73-bfd040c76b9c', ' Eens', ' Eerder eens',\n",
       "        ' Eerder eens', ' Eens', ' Eens', nan, nan, ' Eens', ' Eens',\n",
       "        ' Helemaal eens', nan, nan, ' Eens', ' Helemaal eens', ' Eens',\n",
       "        nan, nan, ' Helemaal eens', nan, nan, ' Eerder eens',\n",
       "        ' Eerder eens', nan, nan, ' Eerder oneens',\n",
       "        'Misschien heb ik erover gekeken maar ik heb nog niet echt een uitleg hierover gezien.',\n",
       "        nan, ' Helemaal oneens', ' Neutraal', ' Oneens', ' Eens', nan,\n",
       "        nan, 1893, 2, ' 4e middelbaar'],\n",
       "       [17, 18, 47, '04/26/2021 - 20:48', '04/26/2021 - 20:48',\n",
       "        '04/26/2021 - 20:48', 0, 1899,\n",
       "        'afe131d1-4f72-4f1c-991b-3c279ee4cf05', ' Eens', ' Neutraal',\n",
       "        ' Neutraal', ' Eerder oneens', ' Eerder eens', nan, nan, ' Eens',\n",
       "        ' Eens', ' Eens', nan, nan, ' Eens', ' Eens', ' Eens', nan, nan,\n",
       "        ' Eerder eens', nan, nan, ' Eens', ' Eerder eens', nan, nan,\n",
       "        ' Oneens',\n",
       "        'Ik heb nog geen uitleg gezien maar misschien ben ik het gewoon overgeslagen',\n",
       "        nan, ' Helemaal oneens', ' Neutraal', ' Eerder oneens', ' Eens',\n",
       "        'Het zou handig zijn als hij zegt hoe je tot een uitkomst komt',\n",
       "        nan, 1899, 2, ' 4e middelbaar'],\n",
       "       [18, 19, 48, '04/26/2021 - 21:10', '04/26/2021 - 21:10',\n",
       "        '04/26/2021 - 21:10', 0, 1892,\n",
       "        'e244cd29-3681-45d8-b044-8d5c0f0c4df3', ' Neutraal',\n",
       "        ' Eerder oneens', ' Eerder oneens', ' Eerder eens', ' Neutraal',\n",
       "        nan, nan, ' Eerder eens', ' Eerder oneens', ' Eerder eens', nan,\n",
       "        nan, ' Eerder eens', ' Helemaal eens', ' Eens', nan, nan,\n",
       "        ' Eerder oneens', nan, nan, ' Eerder eens', ' Eerder oneens',\n",
       "        nan, nan, ' Oneens',\n",
       "        'ik vind het heel handig dat er gemiddeld en moeilijk enz bij de oefeningen staan.',\n",
       "        nan, ' Oneens', ' Eerder eens', ' Neutraal', ' Eerder eens', nan,\n",
       "        nan, 1892, 2, ' 4e middelbaar'],\n",
       "       [24, 25, 76, '04/29/2021 - 21:55', '04/29/2021 - 21:55',\n",
       "        '04/29/2021 - 21:55', 0, 1921,\n",
       "        '0bb1cb77-cee8-49cb-98ee-6396a5d7859f', ' Neutraal', ' Eens',\n",
       "        ' Eerder eens', ' Eerder oneens', ' Eerder eens', 'nee', nan,\n",
       "        ' Eens', ' Eens', ' Eerder eens', 'Neen', nan, ' Neutraal',\n",
       "        ' Eerder eens', ' Neutraal', 'Nee', nan, ' Eerder oneens', 'Nee',\n",
       "        nan, ' Eerder eens', ' Eerder eens', 'Nee', nan, ' Neutraal',\n",
       "        'Ik heb dit precies gemist', nan, ' Eerder oneens', ' Neutraal',\n",
       "        ' Eerder eens', ' Eerder eens', 'Zeer goede site!', nan, 1921, 2,\n",
       "        ' 5e middelbaar'],\n",
       "       [29, 30, 101, '05/04/2021 - 15:00', '05/04/2021 - 15:00',\n",
       "        '05/04/2021 - 15:00', 0, 1941,\n",
       "        '60fc8d43-e908-4752-ae42-242e87caca1d', ' Eens', ' Eens',\n",
       "        ' Eens', ' Eerder eens', ' Helemaal eens', nan, nan, ' Neutraal',\n",
       "        ' Eerder eens', ' Eens', nan, nan, ' Helemaal eens', ' Eens',\n",
       "        ' Helemaal eens', nan, nan, ' Eens', nan, nan, ' Eerder eens',\n",
       "        ' Helemaal eens', nan, nan, ' Neutraal',\n",
       "        'Ik heb nog geen uitleg gezien, maar ik heb er ook nog geen nodig gehad.',\n",
       "        nan, ' Neutraal', ' Eerder eens', ' Oneens', ' Eerder eens', nan,\n",
       "        nan, 1941, 2, ' 6e middelbaar'],\n",
       "       [32, 33, 104, '05/04/2021 - 15:26', '05/04/2021 - 15:26',\n",
       "        '05/04/2021 - 15:26', 0, 1944,\n",
       "        '7abfdaf1-c6e8-41a4-9557-5870f8d3dea6', ' Eerder eens',\n",
       "        ' Eerder eens', ' Eerder eens', ' Eens', ' Eens', nan, nan,\n",
       "        ' Eerder eens', ' Eerder eens', ' Eens', nan, nan,\n",
       "        ' Eerder eens', ' Eens', ' Eens', nan, nan, ' Eens', nan, nan,\n",
       "        ' Eens', ' Eens', nan, nan, ' Eerder oneens',\n",
       "        'Ik heb nergens gelezen waarom een oefening aan mij werd aangeraden. ',\n",
       "        '(Misschien moest ik hiervoor ergens op klikken en heb ik dit niet gezien. Ik had niet verwacht dat er uitleg zou komen waarom een oefening aangeraden is, misschien heb ik het gewoon niet gezien.',\n",
       "        ' Oneens', ' Neutraal', ' Oneens', ' Eerder eens', nan, nan,\n",
       "        1944, 2, ' 6e middelbaar'],\n",
       "       [36, 37, 111, '05/08/2021 - 12:01', '05/08/2021 - 12:01',\n",
       "        '05/08/2021 - 12:01', 0, 1948,\n",
       "        '590bd5df-51c9-4719-a1b0-99c42332b16d', ' Eerder eens',\n",
       "        ' Eerder oneens', ' Eerder oneens', ' Eerder oneens',\n",
       "        ' Eerder oneens', nan, nan, ' Eens', ' Eerder eens',\n",
       "        ' Eerder oneens', nan, nan, ' Eerder eens', ' Helemaal eens',\n",
       "        ' Eerder oneens', nan, nan, ' Eerder oneens', nan, nan,\n",
       "        ' Neutraal', ' Neutraal', nan, nan, ' Eens',\n",
       "        'Als je een nieuwe oefening wilt maken is het handig dat je weet waarom deze oefening aangeraden wordt, dit doet de website goed.',\n",
       "        nan, ' Oneens', ' Eerder eens', ' Eens', ' Eens', nan, nan, 1948,\n",
       "        2, ' 6e middelbaar'],\n",
       "       [37, 38, 113, '05/08/2021 - 14:27', '05/08/2021 - 14:27',\n",
       "        '05/08/2021 - 14:27', 0, 1949,\n",
       "        '9f986eab-3561-4f74-be3a-94567e10ee36', ' Eens', ' Eens',\n",
       "        ' Eens', ' Eerder eens', ' Eens', 'neen', nan, ' Eens',\n",
       "        ' Eerder eens', ' Eerder eens', nan, nan, ' Eens',\n",
       "        ' Helemaal eens', ' Eens', nan, nan, ' Eens', nan, nan,\n",
       "        ' Eerder eens', ' Eens', nan, nan, ' Eerder oneens',\n",
       "        'Ik kreeg geen uitleg waarom het werd aangeraden', nan,\n",
       "        ' Neutraal', ' Eerder oneens', ' Helemaal oneens', ' Eens',\n",
       "        'Ik vind het niveau van de oefeningen van Wiski goed.',\n",
       "        'de oefeningen komen goed overeen met de oefeningen van in de les, dus het is handig om deze extra te maken voor een test.',\n",
       "        1949, 2, ' 5e middelbaar'],\n",
       "       [39, 40, 117, '05/08/2021 - 20:21', '05/08/2021 - 20:21',\n",
       "        '05/08/2021 - 20:21', 0, 1950,\n",
       "        '48c44361-6c02-4a4b-bea7-8ca00cb3664a', ' Eerder eens', ' Eens',\n",
       "        ' Eens', ' Eerder eens', ' Helemaal eens', nan, nan, ' Eens',\n",
       "        ' Eens', ' Helemaal eens', nan, nan, ' Eens', ' Helemaal eens',\n",
       "        ' Helemaal eens', nan, nan, ' Eens', nan, nan, ' Eens',\n",
       "        ' Helemaal eens', nan, nan, ' Oneens',\n",
       "        'Ik heb geen uitleg gezien. Er stond gewoon dat het aangereden werd. ',\n",
       "        nan, ' Eerder oneens', ' Eens', ' Helemaal oneens', ' Eens', nan,\n",
       "        'Ik vind het een heel gebruiksvriendelijke site, ik kan er goed mee omgaan en het verloopt volt. Ik vind het wel spijtig dat er niet staat waarom een bepaalde oefening aangeraden wordt. Het is fijn om te weten waarom die oefening bij jou past, maar er moet ook niet te veel info in staan want dan is het niet meer leuk om te lezen.',\n",
       "        1950, 2, ' 4e middelbaar'],\n",
       "       [44, 45, 135, '05/14/2021 - 15:39', '05/14/2021 - 15:39',\n",
       "        '05/14/2021 - 15:39', 0, 1967,\n",
       "        'c1d65f48-3d83-45d3-bd00-6a0882387e43', ' Neutraal',\n",
       "        ' Eerder eens', ' Eerder eens', ' Eens', ' Eerder eens', nan,\n",
       "        nan, ' Neutraal', ' Eerder eens', ' Eens', nan, nan, ' Eens',\n",
       "        ' Helemaal eens', ' Eens', nan, nan, ' Eens', nan, nan,\n",
       "        ' Neutraal', ' Neutraal', nan, nan, ' Eerder eens',\n",
       "        'Ja ik vind dat er genoeg uitleg is.', nan, ' Helemaal oneens',\n",
       "        ' Neutraal', ' Helemaal oneens', ' Helemaal eens', nan, nan,\n",
       "        1967, 2, ' 5e middelbaar'],\n",
       "       [46, 47, 139, '05/15/2021 - 12:09', '05/15/2021 - 12:09',\n",
       "        '05/15/2021 - 12:09', 0, 1969,\n",
       "        'd3e646a6-f5e3-44dd-8e91-94a88b838495', ' Eens',\n",
       "        ' Helemaal eens', ' Helemaal eens', ' Eens', ' Helemaal eens',\n",
       "        nan, '\\n', ' Eens', ' Eerder eens', ' Helemaal eens', nan, nan,\n",
       "        ' Eens', ' Helemaal eens', ' Helemaal eens', nan, nan,\n",
       "        ' Helemaal eens', nan, nan, ' Helemaal eens', ' Helemaal eens',\n",
       "        nan, nan, ' Eerder oneens',\n",
       "        \"Ik kan nergens echt vinden 'waarom' een oefening wordt aangeraden.\",\n",
       "        \"Ik had bij de vorige vragenlijst aangeduid dat ik mezelf 'gemiddeld' vind in wiskunde, en ik heb (daardoor denk ik maar weet ik niet zeker) enkel 'gemiddeld' oefeningen gekregen. Misschien dat het beter zou zijn als je bijvoorbeeld net begonnen bent met studeren dat je enkele makkelijke oefeningen kan maken om het 'op te frissen' of 'met een goed gevoel te beginnen' of andersom, dat je graag jezelf uitdaagt en een moeilijke oefening wil proberen (als de aanbevelingen van gemiddeld niks te maken hadden met wat ik had aangeduid op die vorige enquete dan mag je deze uitleg gewoon negeren :))\",\n",
       "        ' Helemaal oneens', ' Oneens', ' Helemaal oneens',\n",
       "        ' Helemaal eens',\n",
       "        'Ik vind uitleg krijgen waarom iets aangeraden wordt altijd wel fijner omdat je dan weet waarom je dat eigenlijk aan het maken ',\n",
       "        'bent', 1969, 2, ' 5e middelbaar']], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nothing_df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Tests\n",
    "- Non parametric tests: Mann Whitney, Kruskal Wallis, ... -> No need for normal distribution but need enough people\n",
    "- Parametric test: t-test -> Small number of people ok but need normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "# rqv\n",
    "# pqv\n",
    "# nqv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_likert_to_int(key):\n",
    "    if key == \"Helemaal oneens\":\n",
    "        return 1\n",
    "    elif key == \"Oneens\":\n",
    "        return 2\n",
    "    elif key == \"Eerder oneens\":\n",
    "        return 3\n",
    "    elif key == \"Neutraal\":\n",
    "        return 4\n",
    "    elif key == \"Eerder eens\":\n",
    "        return 5\n",
    "    elif key == \"Eens\":\n",
    "        return 6\n",
    "    elif key == \"Helemaal eens\":\n",
    "        return 7\n",
    "def list_scores_competence(df):\n",
    "    competence_scores = []\n",
    "    for i in range(len(df)):\n",
    "        row = df.iloc[i]\n",
    "        score = 0\n",
    "        score += int(map_likert_to_int(row[q1].strip()))\n",
    "        score += int(map_likert_to_int(row[q2].strip()))\n",
    "        score += int(map_likert_to_int(row[q3].strip()))\n",
    "        score += int(map_likert_to_int(row[q4].strip()))\n",
    "        score += int(map_likert_to_int(row[q5].strip()))\n",
    "        competence_scores.append(score)\n",
    "    return competence_scores\n",
    "def list_scores_benevolence(df):\n",
    "    benevolence_scores = []\n",
    "    for i in range(len(df)):\n",
    "        row = df.iloc[i]\n",
    "        score = 0\n",
    "        score += int(map_likert_to_int(row[q6].strip()))\n",
    "        score += int(map_likert_to_int(row[q7].strip()))\n",
    "        score += int(map_likert_to_int(row[q8].strip()))\n",
    "        benevolence_scores.append(score)\n",
    "    return benevolence_scores\n",
    "def list_scores_integrity(df):\n",
    "    integrity_scores = []\n",
    "    for i in range(len(df)):\n",
    "        row = df.iloc[i]\n",
    "        score = 0\n",
    "        score += int(map_likert_to_int(row[q9].strip()))\n",
    "        score += int(map_likert_to_int(row[q10].strip()))\n",
    "        score += int(map_likert_to_int(row[q11].strip()))\n",
    "        integrity_scores.append(score)\n",
    "    return integrity_scores       \n",
    "def list_scores_trusting_beliefs(competence, benevolence, integrity):\n",
    "    trusting_beliefs = [competence[i]/5+benevolence[i]/3+integrity[i]/3 for i in range(len(competence))]\n",
    "    return trusting_beliefs\n",
    "def list_scores_perceived_transparency(df):\n",
    "    pt_scores = []\n",
    "    for i in range(len(df)):\n",
    "        row = df.iloc[i]\n",
    "        score = 0\n",
    "        score += int(map_likert_to_int(row[q15].strip()))\n",
    "        pt_scores.append(score)\n",
    "    return pt_scores\n",
    "def list_scores_intention_to_return(df):\n",
    "    itr_scores = []\n",
    "    for i in range(len(df)):\n",
    "        row = df.iloc[i]\n",
    "        score = 0\n",
    "        score += int(map_likert_to_int(row[q13].strip()))\n",
    "        score += int(map_likert_to_int(row[q14].strip()))\n",
    "        itr_scores.append(score)\n",
    "    return itr_scores\n",
    "def list_scores_single_q(df, q_number):\n",
    "    scores = []\n",
    "    for i in range(len(df)):\n",
    "        row = df.iloc[i]\n",
    "        score = 0\n",
    "        score += int(map_likert_to_int(row[q_number].strip()))\n",
    "        scores.append(score)\n",
    "    return scores\n",
    "def list_scores_md_trust(trusting_beliefs, intention_to_return, perceived_transparency):\n",
    "    return [trusting_beliefs[i]/3 + intention_to_return[i]/2 + perceived_transparency[i] for i in range(len(trusting_beliefs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.3999999999999995, 6.177777777777778, 5.866666666666667, 6.8, 5.133333333333333, 5.888888888888889, 6.288888888888889, 6.066666666666666, 6.177777777777778, 5.8, 6.222222222222222, 4.222222222222222]\n"
     ]
    }
   ],
   "source": [
    "competence_scores_real = list_scores_competence(real_df)\n",
    "competence_scores_placebo = list_scores_competence(placebo_df)\n",
    "competence_scores_nothing = list_scores_competence(nothing_df)\n",
    "competence_scores = [competence_scores_real, competence_scores_placebo, competence_scores_nothing]\n",
    "\n",
    "\n",
    "benevolence_scores_real = list_scores_benevolence(real_df)\n",
    "benevolence_scores_placebo = list_scores_benevolence(placebo_df)\n",
    "benevolence_scores_nothing = list_scores_benevolence(nothing_df)\n",
    "benevolence_scores = [benevolence_scores_real, benevolence_scores_placebo, benevolence_scores_nothing]\n",
    "\n",
    "\n",
    "integrity_scores_real = list_scores_integrity(real_df)\n",
    "integrity_scores_placebo = list_scores_integrity(placebo_df)\n",
    "integrity_scores_nothing = list_scores_integrity(nothing_df)\n",
    "integrity_scores = [integrity_scores_real, integrity_scores_placebo, integrity_scores_nothing]\n",
    "\n",
    "\n",
    "trusting_beliefs_scores_real = list_scores_trusting_beliefs(competence_scores_real, benevolence_scores_real, integrity_scores_real)\n",
    "trusting_beliefs_scores_placebo = list_scores_trusting_beliefs(competence_scores_placebo, benevolence_scores_placebo, integrity_scores_placebo)\n",
    "trusting_beliefs_scores_nothing = list_scores_trusting_beliefs(competence_scores_nothing, benevolence_scores_nothing, integrity_scores_nothing)\n",
    "trusting_beliefs_scores = [trusting_beliefs_scores_real, trusting_beliefs_scores_placebo, trusting_beliefs_scores_nothing]\n",
    "\n",
    "\n",
    "itr_scores_real = list_scores_intention_to_return(real_df)\n",
    "itr_scores_placebo = list_scores_intention_to_return(placebo_df)\n",
    "itr_scores_nothing = list_scores_intention_to_return(nothing_df)\n",
    "itr_scores = [itr_scores_real, itr_scores_placebo, itr_scores_nothing]\n",
    "\n",
    "\n",
    "pt_scores_real = list_scores_perceived_transparency(real_df)\n",
    "pt_scores_placebo = list_scores_perceived_transparency(placebo_df)\n",
    "pt_scores_nothing = list_scores_perceived_transparency(nothing_df)\n",
    "pt_scores = [pt_scores_real, pt_scores_placebo, pt_scores_nothing]\n",
    "\n",
    "explicit_trust_scores_real = list_scores_single_q(real_df, q12)\n",
    "explicit_trust_scores_placebo = list_scores_single_q(placebo_df, q12)\n",
    "explicit_trust_scores_nothing = list_scores_single_q(nothing_df, q12)\n",
    "explicit_trust_scores = [explicit_trust_scores_real, explicit_trust_scores_placebo, explicit_trust_scores_nothing]\n",
    "\n",
    "\n",
    "md_trust_scores_real = list_scores_md_trust(trusting_beliefs_scores_real, itr_scores_real, pt_scores_real)\n",
    "md_trust_scores_placebo = list_scores_md_trust(trusting_beliefs_scores_placebo, itr_scores_placebo, pt_scores_placebo)\n",
    "md_trust_scores_nothing = list_scores_md_trust(trusting_beliefs_scores_nothing, itr_scores_nothing, pt_scores_nothing)\n",
    "md_trust_scores = [md_trust_scores_real, md_trust_scores_placebo, md_trust_scores_nothing]\n",
    "print([i/3 for i in trusting_beliefs_scores_real])\n",
    "\n",
    "q16_scores_real = list_scores_single_q(real_df, q16)\n",
    "q16_scores_placebo = list_scores_single_q(placebo_df, q16)\n",
    "q16_scores_nothing = list_scores_single_q(nothing_df, q16)\n",
    "q16_scores = [q16_scores_real, q16_scores_placebo, q16_scores_nothing]\n",
    "\n",
    "\n",
    "q17_scores_real = list_scores_single_q(real_df, q17)\n",
    "q17_scores_placebo = list_scores_single_q(placebo_df, q17)\n",
    "q17_scores_nothing = list_scores_single_q(nothing_df, q17)\n",
    "q17_scores = [q17_scores_real, q17_scores_placebo, q17_scores_nothing]\n",
    "\n",
    "\n",
    "q18_scores_real = list_scores_single_q(real_df, q18)\n",
    "q18_scores_placebo = list_scores_single_q(placebo_df, q18)\n",
    "q18_scores_nothing = list_scores_single_q(nothing_df, q18)\n",
    "q18_scores = [q18_scores_real, q18_scores_placebo, q18_scores_nothing]\n",
    "\n",
    "\n",
    "q19_scores_real = list_scores_single_q(real_df, q19)\n",
    "q19_scores_placebo = list_scores_single_q(placebo_df, q19)\n",
    "q19_scores_nothing = list_scores_single_q(nothing_df, q19)\n",
    "q19_scores = [q19_scores_real, q19_scores_placebo, q19_scores_nothing]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Independent t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs, cp = stats.ttest_ind(competence_scores_real,competence_scores_placebo)\n",
    "bs, bp = stats.ttest_ind(benevolence_scores_real,benevolence_scores_placebo)\n",
    "ins, inp = stats.ttest_ind(integrity_scores_real,integrity_scores_placebo)\n",
    "tbs, tbp = stats.ttest_ind(trusting_beliefs_scores_real,trusting_beliefs_scores_placebo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mann-Whitney U Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real vs Placebo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mwu_cs, mwu_cp = stats.mannwhitneyu(competence_scores_real,competence_scores_placebo)\n",
    "mwu_bs, mwu_bp = stats.mannwhitneyu(benevolence_scores_real,benevolence_scores_placebo)\n",
    "mwu_ins, mwu_inp = stats.mannwhitneyu(integrity_scores_real,integrity_scores_placebo)\n",
    "mwu_tbs, mwu_tbp = stats.mannwhitneyu(trusting_beliefs_scores_real,trusting_beliefs_scores_placebo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mann-Whitney U Test P-Values (Real vs Placebo)\n",
      "Competence: 0.023418202137543517\n",
      "Benevolence: 0.07427697172266019\n",
      "Integrity: 0.05398308398543777\n",
      "Trusting Beliefs: 0.026471471657635522\n"
     ]
    }
   ],
   "source": [
    "print(\"Mann-Whitney U Test P-Values (Real vs Placebo)\")\n",
    "print(\"Competence: \" + str(mwu_cp))\n",
    "print(\"Benevolence: \" + str(mwu_bp))\n",
    "print(\"Integrity: \" + str(mwu_inp))\n",
    "print(\"Trusting Beliefs: \" + str(mwu_tbp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real vs No Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mann-Whitney U Test P-Values (Real vs No Explanation)\n",
      "Competence: 0.029523663306459245\n",
      "Benevolence: 0.03005578729097404\n",
      "Integrity: 0.26139306749341235\n",
      "Trusting Beliefs: 0.04846333941226539\n"
     ]
    }
   ],
   "source": [
    "mwu_rn_cs, mwu_rn_cp = stats.mannwhitneyu(competence_scores_real,competence_scores_nothing)\n",
    "mwu_rn_bs, mwu_rn_bp = stats.mannwhitneyu(benevolence_scores_real,benevolence_scores_nothing)\n",
    "mwu_rn_ins, mwu_rn_inp = stats.mannwhitneyu(integrity_scores_real,integrity_scores_nothing)\n",
    "mwu_rn_tbs, mwu_rn_tbp = stats.mannwhitneyu(trusting_beliefs_scores_real,trusting_beliefs_scores_nothing)\n",
    "\n",
    "print(\"Mann-Whitney U Test P-Values (Real vs No Explanation)\")\n",
    "print(\"Competence: \" + str(mwu_rn_cp))\n",
    "print(\"Benevolence: \" + str(mwu_rn_bp))\n",
    "print(\"Integrity: \" + str(mwu_rn_inp))\n",
    "print(\"Trusting Beliefs: \" + str(mwu_rn_tbp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_language_effect_size(U, n1, n2):\n",
    "    return U/(n1*n2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mann-Whitney U Test U-Values (Real vs No Explanation)\n",
      "Competence: 43.0\n",
      "Benevolence: 43.5\n",
      "Integrity: 66.0\n",
      "Trusting Beliefs: 47.0\n",
      "Mann-Whitney U Test Common Language Effect Size (Real vs No Explanation)\n",
      "Competence: 0.27564102564102566\n",
      "Benevolence: 0.27884615384615385\n",
      "Integrity: 0.4230769230769231\n",
      "Trusting Beliefs: 0.30128205128205127\n"
     ]
    }
   ],
   "source": [
    "real_n = len(real_df)\n",
    "placebo_n = len(placebo_df)\n",
    "nothing_n = len(nothing_df)\n",
    "\n",
    "print(\"Mann-Whitney U Test U-Values (Real vs No Explanation)\")\n",
    "print(\"Competence: \" + str(mwu_rn_cs))\n",
    "print(\"Benevolence: \" + str(mwu_rn_bs))\n",
    "print(\"Integrity: \" + str(mwu_rn_ins))\n",
    "print(\"Trusting Beliefs: \" + str(mwu_rn_tbs))\n",
    "\n",
    "print(\"Mann-Whitney U Test Common Language Effect Size (Real vs No Explanation)\")\n",
    "print(\"Competence: \" + str(common_language_effect_size(mwu_rn_cs, real_n, nothing_n)))\n",
    "print(\"Benevolence: \" + str(common_language_effect_size(mwu_rn_bs, real_n, nothing_n)))\n",
    "print(\"Integrity: \" + str(common_language_effect_size(mwu_rn_ins, real_n, nothing_n)))\n",
    "print(\"Trusting Beliefs: \" + str(common_language_effect_size(mwu_rn_tbs, real_n, nothing_n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pingouin as pg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pingouin MWU Real vs No Explanation Competence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Sho/opt/anaconda3/lib/python3.8/site-packages/outdated/utils.py:14: OutdatedPackageWarning: The package outdated is out of date. Your version is 0.2.0, the latest is 0.2.1.\n",
      "Set the environment variable OUTDATED_IGNORE=1 to disable these warnings.\n",
      "  return warn(\n",
      "/Users/Sho/opt/anaconda3/lib/python3.8/site-packages/outdated/utils.py:14: OutdatedPackageWarning: The package pingouin is out of date. Your version is 0.3.11, the latest is 0.5.0.\n",
      "Set the environment variable OUTDATED_IGNORE=1 to disable these warnings.\n",
      "  return warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>U-val</th>\n",
       "      <th>tail</th>\n",
       "      <th>p-val</th>\n",
       "      <th>RBC</th>\n",
       "      <th>CLES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MWU</th>\n",
       "      <td>113.0</td>\n",
       "      <td>greater</td>\n",
       "      <td>0.029524</td>\n",
       "      <td>-0.448718</td>\n",
       "      <td>0.724359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     U-val     tail     p-val       RBC      CLES\n",
       "MWU  113.0  greater  0.029524 -0.448718  0.724359"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg.mwu(competence_scores_real,competence_scores_nothing, tail='one-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pingouin MWU Real vs No Explanation Benevolence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>U-val</th>\n",
       "      <th>tail</th>\n",
       "      <th>p-val</th>\n",
       "      <th>RBC</th>\n",
       "      <th>CLES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MWU</th>\n",
       "      <td>112.5</td>\n",
       "      <td>greater</td>\n",
       "      <td>0.030056</td>\n",
       "      <td>-0.442308</td>\n",
       "      <td>0.721154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     U-val     tail     p-val       RBC      CLES\n",
       "MWU  112.5  greater  0.030056 -0.442308  0.721154"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg.mwu(benevolence_scores_real,benevolence_scores_nothing, tail='one-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pingouin MWU Real vs No Explanation Integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>U-val</th>\n",
       "      <th>tail</th>\n",
       "      <th>p-val</th>\n",
       "      <th>RBC</th>\n",
       "      <th>CLES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MWU</th>\n",
       "      <td>90.0</td>\n",
       "      <td>greater</td>\n",
       "      <td>0.261393</td>\n",
       "      <td>-0.153846</td>\n",
       "      <td>0.576923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     U-val     tail     p-val       RBC      CLES\n",
       "MWU   90.0  greater  0.261393 -0.153846  0.576923"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg.mwu(integrity_scores_real,integrity_scores_nothing, tail='one-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pingouin MWU Real vs No Explanation Trusting Beliefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>U-val</th>\n",
       "      <th>tail</th>\n",
       "      <th>p-val</th>\n",
       "      <th>RBC</th>\n",
       "      <th>CLES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MWU</th>\n",
       "      <td>109.0</td>\n",
       "      <td>greater</td>\n",
       "      <td>0.048463</td>\n",
       "      <td>-0.397436</td>\n",
       "      <td>0.698718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     U-val     tail     p-val       RBC      CLES\n",
       "MWU  109.0  greater  0.048463 -0.397436  0.698718"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg.mwu(trusting_beliefs_scores_real,trusting_beliefs_scores_nothing, tail='one-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pingouin MWU Real vs No Explanation Perceived Transparency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>U-val</th>\n",
       "      <th>tail</th>\n",
       "      <th>p-val</th>\n",
       "      <th>RBC</th>\n",
       "      <th>CLES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MWU</th>\n",
       "      <td>130.5</td>\n",
       "      <td>greater</td>\n",
       "      <td>0.001943</td>\n",
       "      <td>-0.673077</td>\n",
       "      <td>0.836538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     U-val     tail     p-val       RBC      CLES\n",
       "MWU  130.5  greater  0.001943 -0.673077  0.836538"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg.mwu(pt_scores_real,pt_scores_nothing, tail='one-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pingouin MWU Real vs No Explanation Intention to Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>U-val</th>\n",
       "      <th>tail</th>\n",
       "      <th>p-val</th>\n",
       "      <th>RBC</th>\n",
       "      <th>CLES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MWU</th>\n",
       "      <td>100.5</td>\n",
       "      <td>greater</td>\n",
       "      <td>0.108697</td>\n",
       "      <td>-0.288462</td>\n",
       "      <td>0.644231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     U-val     tail     p-val       RBC      CLES\n",
       "MWU  100.5  greater  0.108697 -0.288462  0.644231"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg.mwu(itr_scores_real,itr_scores_nothing, tail='one-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pingouin MWU Real vs No Explanation Multi-Dimensional Trust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>U-val</th>\n",
       "      <th>tail</th>\n",
       "      <th>p-val</th>\n",
       "      <th>RBC</th>\n",
       "      <th>CLES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MWU</th>\n",
       "      <td>131.0</td>\n",
       "      <td>greater</td>\n",
       "      <td>0.002148</td>\n",
       "      <td>-0.679487</td>\n",
       "      <td>0.839744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     U-val     tail     p-val       RBC      CLES\n",
       "MWU  131.0  greater  0.002148 -0.679487  0.839744"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg.mwu(md_trust_scores_real,md_trust_scores_nothing, tail='one-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pingouin MWU Real vs No Explanation Explicit Trust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>U-val</th>\n",
       "      <th>tail</th>\n",
       "      <th>p-val</th>\n",
       "      <th>RBC</th>\n",
       "      <th>CLES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MWU</th>\n",
       "      <td>97.5</td>\n",
       "      <td>greater</td>\n",
       "      <td>0.137224</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     U-val     tail     p-val   RBC   CLES\n",
       "MWU   97.5  greater  0.137224 -0.25  0.625"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg.mwu(explicit_trust_scores_real,explicit_trust_scores_nothing, tail='one-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placebo vs No Explanation Competence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>U-val</th>\n",
       "      <th>tail</th>\n",
       "      <th>p-val</th>\n",
       "      <th>RBC</th>\n",
       "      <th>CLES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MWU</th>\n",
       "      <td>78.0</td>\n",
       "      <td>two-sided</td>\n",
       "      <td>0.978215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     U-val       tail     p-val  RBC  CLES\n",
       "MWU   78.0  two-sided  0.978215  0.0   0.5"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg.mwu(competence_scores_placebo,competence_scores_nothing, tail='two-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placebo vs No Explanation Benevolence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>U-val</th>\n",
       "      <th>tail</th>\n",
       "      <th>p-val</th>\n",
       "      <th>RBC</th>\n",
       "      <th>CLES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MWU</th>\n",
       "      <td>78.0</td>\n",
       "      <td>two-sided</td>\n",
       "      <td>0.977935</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     U-val       tail     p-val  RBC  CLES\n",
       "MWU   78.0  two-sided  0.977935  0.0   0.5"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg.mwu(benevolence_scores_placebo,benevolence_scores_nothing, tail='two-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placebo vs No Explanation Integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>U-val</th>\n",
       "      <th>tail</th>\n",
       "      <th>p-val</th>\n",
       "      <th>RBC</th>\n",
       "      <th>CLES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MWU</th>\n",
       "      <td>51.0</td>\n",
       "      <td>two-sided</td>\n",
       "      <td>0.143084</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.326923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     U-val       tail     p-val       RBC      CLES\n",
       "MWU   51.0  two-sided  0.143084  0.346154  0.326923"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg.mwu(integrity_scores_placebo,integrity_scores_nothing, tail='two-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placebo vs No Explanation Trusting Beliefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>U-val</th>\n",
       "      <th>tail</th>\n",
       "      <th>p-val</th>\n",
       "      <th>RBC</th>\n",
       "      <th>CLES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MWU</th>\n",
       "      <td>69.5</td>\n",
       "      <td>two-sided</td>\n",
       "      <td>0.663277</td>\n",
       "      <td>0.108974</td>\n",
       "      <td>0.445513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     U-val       tail     p-val       RBC      CLES\n",
       "MWU   69.5  two-sided  0.663277  0.108974  0.445513"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg.mwu(trusting_beliefs_scores_placebo,trusting_beliefs_scores_nothing, tail='two-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placebo vs No Explanation Intention to Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>U-val</th>\n",
       "      <th>tail</th>\n",
       "      <th>p-val</th>\n",
       "      <th>RBC</th>\n",
       "      <th>CLES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MWU</th>\n",
       "      <td>85.5</td>\n",
       "      <td>two-sided</td>\n",
       "      <td>0.696413</td>\n",
       "      <td>-0.096154</td>\n",
       "      <td>0.548077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     U-val       tail     p-val       RBC      CLES\n",
       "MWU   85.5  two-sided  0.696413 -0.096154  0.548077"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg.mwu(itr_scores_placebo,itr_scores_nothing, tail='two-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placebo vs No Explanation Perceived Transparency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>U-val</th>\n",
       "      <th>tail</th>\n",
       "      <th>p-val</th>\n",
       "      <th>RBC</th>\n",
       "      <th>CLES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MWU</th>\n",
       "      <td>108.0</td>\n",
       "      <td>two-sided</td>\n",
       "      <td>0.099159</td>\n",
       "      <td>-0.384615</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     U-val       tail     p-val       RBC      CLES\n",
       "MWU  108.0  two-sided  0.099159 -0.384615  0.692308"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg.mwu(pt_scores_placebo,pt_scores_nothing, tail='two-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placebo vs No Explanation Explicit Trust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>U-val</th>\n",
       "      <th>tail</th>\n",
       "      <th>p-val</th>\n",
       "      <th>RBC</th>\n",
       "      <th>CLES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MWU</th>\n",
       "      <td>71.5</td>\n",
       "      <td>two-sided</td>\n",
       "      <td>0.728316</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.458333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     U-val       tail     p-val       RBC      CLES\n",
       "MWU   71.5  two-sided  0.728316  0.083333  0.458333"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg.mwu(explicit_trust_scores_placebo,explicit_trust_scores_nothing, tail='two-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placebo vs No Explanation Multi-Dimensional Trust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>U-val</th>\n",
       "      <th>tail</th>\n",
       "      <th>p-val</th>\n",
       "      <th>RBC</th>\n",
       "      <th>CLES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MWU</th>\n",
       "      <td>96.5</td>\n",
       "      <td>two-sided</td>\n",
       "      <td>0.327452</td>\n",
       "      <td>-0.237179</td>\n",
       "      <td>0.61859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     U-val       tail     p-val       RBC     CLES\n",
       "MWU   96.5  two-sided  0.327452 -0.237179  0.61859"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg.mwu(md_trust_scores_placebo, md_trust_scores_nothing, tail='two-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real vs Placebo Competence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>U-val</th>\n",
       "      <th>tail</th>\n",
       "      <th>p-val</th>\n",
       "      <th>RBC</th>\n",
       "      <th>CLES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MWU</th>\n",
       "      <td>37.5</td>\n",
       "      <td>less</td>\n",
       "      <td>0.023418</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>0.739583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     U-val  tail     p-val       RBC      CLES\n",
       "MWU   37.5  less  0.023418  0.479167  0.739583"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg.mwu(competence_scores_placebo,competence_scores_real, tail='one-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real vs Placebo Benevolence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>U-val</th>\n",
       "      <th>tail</th>\n",
       "      <th>p-val</th>\n",
       "      <th>RBC</th>\n",
       "      <th>CLES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MWU</th>\n",
       "      <td>47.0</td>\n",
       "      <td>less</td>\n",
       "      <td>0.074277</td>\n",
       "      <td>0.347222</td>\n",
       "      <td>0.673611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     U-val  tail     p-val       RBC      CLES\n",
       "MWU   47.0  less  0.074277  0.347222  0.673611"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg.mwu(benevolence_scores_placebo,benevolence_scores_real, tail='one-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real vs Placebo Integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>U-val</th>\n",
       "      <th>tail</th>\n",
       "      <th>p-val</th>\n",
       "      <th>RBC</th>\n",
       "      <th>CLES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MWU</th>\n",
       "      <td>44.0</td>\n",
       "      <td>less</td>\n",
       "      <td>0.053983</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.694444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     U-val  tail     p-val       RBC      CLES\n",
       "MWU   44.0  less  0.053983  0.388889  0.694444"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg.mwu(integrity_scores_placebo,integrity_scores_real, tail='one-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real vs Placebo Trusting Beliefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>U-val</th>\n",
       "      <th>tail</th>\n",
       "      <th>p-val</th>\n",
       "      <th>RBC</th>\n",
       "      <th>CLES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MWU</th>\n",
       "      <td>38.0</td>\n",
       "      <td>less</td>\n",
       "      <td>0.026471</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.736111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     U-val  tail     p-val       RBC      CLES\n",
       "MWU   38.0  less  0.026471  0.472222  0.736111"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg.mwu(trusting_beliefs_scores_placebo,trusting_beliefs_scores_real, tail='one-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real vs Placebo Intention to Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>U-val</th>\n",
       "      <th>tail</th>\n",
       "      <th>p-val</th>\n",
       "      <th>RBC</th>\n",
       "      <th>CLES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MWU</th>\n",
       "      <td>54.0</td>\n",
       "      <td>less</td>\n",
       "      <td>0.139415</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     U-val  tail     p-val   RBC   CLES\n",
       "MWU   54.0  less  0.139415  0.25  0.625"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg.mwu(itr_scores_placebo,itr_scores_real, tail='one-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real vs Placebo Perceived Transparency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>U-val</th>\n",
       "      <th>tail</th>\n",
       "      <th>p-val</th>\n",
       "      <th>RBC</th>\n",
       "      <th>CLES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MWU</th>\n",
       "      <td>42.0</td>\n",
       "      <td>less</td>\n",
       "      <td>0.041183</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     U-val  tail     p-val       RBC      CLES\n",
       "MWU   42.0  less  0.041183  0.416667  0.708333"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg.mwu(pt_scores_placebo,pt_scores_real, tail='one-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real vs Placebo Explicit Trust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>U-val</th>\n",
       "      <th>tail</th>\n",
       "      <th>p-val</th>\n",
       "      <th>RBC</th>\n",
       "      <th>CLES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MWU</th>\n",
       "      <td>47.5</td>\n",
       "      <td>greater</td>\n",
       "      <td>0.936665</td>\n",
       "      <td>0.340278</td>\n",
       "      <td>0.329861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     U-val     tail     p-val       RBC      CLES\n",
       "MWU   47.5  greater  0.936665  0.340278  0.329861"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg.mwu(explicit_trust_scores_placebo,explicit_trust_scores_real, tail='one-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real vs Placebo Multi-Dimensional Trust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>U-val</th>\n",
       "      <th>tail</th>\n",
       "      <th>p-val</th>\n",
       "      <th>RBC</th>\n",
       "      <th>CLES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MWU</th>\n",
       "      <td>33.0</td>\n",
       "      <td>less</td>\n",
       "      <td>0.013115</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.770833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     U-val  tail     p-val       RBC      CLES\n",
       "MWU   33.0  less  0.013115  0.541667  0.770833"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg.mwu(md_trust_scores_placebo, md_trust_scores_real, tail='one-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Tests for Acceptance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = pd.read_csv(\"../Datasets/likert_response_and_acceptance_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "accep_df = master_df[[\"uid\",\"Acceptance\", \"Research Group\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "acceptance_good_df=accep_df[~accep_df[\"uid\"].isin({1921, 1842, 1892, 1958, 1944, 1950})]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>U-val</th>\n",
       "      <th>tail</th>\n",
       "      <th>p-val</th>\n",
       "      <th>RBC</th>\n",
       "      <th>CLES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MWU</th>\n",
       "      <td>67.0</td>\n",
       "      <td>greater</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>-0.654321</td>\n",
       "      <td>0.82716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     U-val     tail     p-val       RBC     CLES\n",
       "MWU   67.0  greater  0.007117 -0.654321  0.82716"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg.mwu(acceptance_good_df[acceptance_good_df[\"Research Group\"]==\"IRE\"][\"Acceptance\"], acceptance_good_df[acceptance_good_df[\"Research Group\"]==\"INE\"][\"Acceptance\"], tail=\"one-sided\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>U-val</th>\n",
       "      <th>tail</th>\n",
       "      <th>p-val</th>\n",
       "      <th>RBC</th>\n",
       "      <th>CLES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MWU</th>\n",
       "      <td>72.0</td>\n",
       "      <td>greater</td>\n",
       "      <td>0.038551</td>\n",
       "      <td>-0.454545</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     U-val     tail     p-val       RBC      CLES\n",
       "MWU   72.0  greater  0.038551 -0.454545  0.727273"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg.mwu(acceptance_good_df[acceptance_good_df[\"Research Group\"]==\"IPE\"][\"Acceptance\"], acceptance_good_df[acceptance_good_df[\"Research Group\"]==\"INE\"][\"Acceptance\"], tail=\"one-sided\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>U-val</th>\n",
       "      <th>tail</th>\n",
       "      <th>p-val</th>\n",
       "      <th>RBC</th>\n",
       "      <th>CLES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MWU</th>\n",
       "      <td>60.0</td>\n",
       "      <td>greater</td>\n",
       "      <td>0.184972</td>\n",
       "      <td>-0.212121</td>\n",
       "      <td>0.606061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     U-val     tail     p-val       RBC      CLES\n",
       "MWU   60.0  greater  0.184972 -0.212121  0.606061"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg.mwu(acceptance_good_df[acceptance_good_df[\"Research Group\"]==\"IRE\"][\"Acceptance\"], acceptance_good_df[acceptance_good_df[\"Research Group\"]==\"IPE\"][\"Acceptance\"], tail=\"one-sided\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(qv):\n",
    "    result = [] # each index is the question. each element is list of likert responses\n",
    "    for dic in qv: # get amount for each question\n",
    "        to_add = []\n",
    "        for i in range(1,8): # [#helemaal oneens, ... , #helemaal eens]\n",
    "            amount = dic.get(i, 0)\n",
    "            to_add.append(amount)\n",
    "        result.append(to_add)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 1, 0, 2, 9, 0], [0, 0, 1, 1, 3, 6, 1], [0, 1, 0, 1, 1, 7, 2], [0, 0, 0, 2, 1, 7, 2], [0, 0, 1, 0, 3, 3, 5], [0, 0, 0, 0, 2, 8, 2], [0, 0, 0, 2, 3, 6, 1], [0, 0, 0, 0, 0, 6, 6], [0, 0, 0, 0, 2, 8, 2], [0, 0, 0, 1, 4, 1, 6], [0, 0, 0, 1, 0, 5, 6], [0, 0, 1, 0, 2, 5, 4], [0, 0, 0, 2, 2, 6, 2], [0, 0, 0, 1, 2, 8, 1], [0, 0, 2, 2, 2, 1, 5], [2, 4, 2, 2, 1, 1, 0], [1, 2, 1, 4, 2, 0, 2], [1, 5, 3, 2, 0, 0, 1], [0, 0, 0, 4, 3, 5, 0]]\n",
      "[[1, 1, 0, 1, 4, 4, 1], [0, 0, 2, 3, 2, 4, 1], [0, 0, 1, 4, 2, 5, 0], [0, 0, 3, 1, 2, 5, 1], [0, 0, 1, 1, 1, 8, 1], [0, 0, 0, 3, 2, 4, 3], [0, 1, 0, 1, 3, 5, 2], [0, 1, 0, 2, 0, 8, 1], [0, 0, 1, 2, 0, 8, 1], [0, 0, 1, 2, 1, 6, 2], [0, 0, 1, 4, 0, 6, 1], [0, 1, 1, 2, 1, 6, 1], [0, 1, 0, 1, 4, 6, 0], [0, 0, 2, 1, 1, 7, 1], [0, 1, 3, 2, 4, 2, 0], [3, 5, 0, 2, 2, 0, 0], [0, 1, 2, 2, 3, 4, 0], [4, 5, 0, 3, 0, 0, 0], [0, 0, 2, 3, 3, 3, 1]]\n",
      "[[0, 0, 0, 3, 5, 5, 0], [0, 0, 2, 1, 5, 4, 1], [0, 0, 2, 1, 5, 4, 1], [0, 0, 3, 0, 5, 5, 0], [0, 0, 1, 1, 4, 4, 3], [0, 0, 0, 2, 3, 8, 0], [0, 0, 1, 1, 6, 5, 0], [0, 0, 1, 0, 3, 6, 3], [0, 0, 0, 1, 4, 7, 1], [0, 0, 0, 0, 1, 5, 7], [0, 0, 1, 1, 1, 7, 3], [0, 0, 3, 0, 2, 6, 2], [0, 0, 0, 2, 7, 3, 1], [0, 0, 1, 2, 5, 2, 3], [0, 3, 5, 3, 1, 1, 0], [4, 3, 2, 4, 0, 0, 0], [0, 1, 2, 5, 4, 1, 0], [4, 5, 1, 1, 1, 1, 0], [0, 0, 0, 2, 4, 5, 2]]\n"
     ]
    }
   ],
   "source": [
    "likert_responses_per_question_real = extract_data(rqv)\n",
    "likert_responses_per_question_placebo = extract_data(pqv)\n",
    "likert_responses_per_question_nothing = extract_data(nqv)\n",
    "print(likert_responses_per_question_real)\n",
    "print(likert_responses_per_question_placebo)\n",
    "print(likert_responses_per_question_nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_q1_4 = [likert_responses_per_question_real[0][4], likert_responses_per_question_placebo[0][4], likert_responses_per_question_nothing[0][4]]\n",
    "test_q1_5 = [likert_responses_per_question_real[0][5], likert_responses_per_question_placebo[0][5], likert_responses_per_question_nothing[0][5]]\n",
    "plt.figure()\n",
    "plt.hist([test_q1_4,test_q1_5], 2, stacked=True, density=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>U-val</th>\n",
       "      <th>tail</th>\n",
       "      <th>p-val</th>\n",
       "      <th>RBC</th>\n",
       "      <th>CLES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MWU</th>\n",
       "      <td>97.0</td>\n",
       "      <td>two-sided</td>\n",
       "      <td>0.295036</td>\n",
       "      <td>-0.24359</td>\n",
       "      <td>0.621795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     U-val       tail     p-val      RBC      CLES\n",
       "MWU   97.0  two-sided  0.295036 -0.24359  0.621795"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg.mwu(q18_scores_real,q18_scores_nothing, tail='two-sided')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>U-val</th>\n",
       "      <th>tail</th>\n",
       "      <th>p-val</th>\n",
       "      <th>RBC</th>\n",
       "      <th>CLES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MWU</th>\n",
       "      <td>72.0</td>\n",
       "      <td>two-sided</td>\n",
       "      <td>0.752552</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     U-val       tail     p-val       RBC      CLES\n",
       "MWU   72.0  two-sided  0.752552  0.076923  0.461538"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg.mwu(q18_scores_placebo,q18_scores_nothing, tail='two-sided')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>U-val</th>\n",
       "      <th>tail</th>\n",
       "      <th>p-val</th>\n",
       "      <th>RBC</th>\n",
       "      <th>CLES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MWU</th>\n",
       "      <td>94.5</td>\n",
       "      <td>two-sided</td>\n",
       "      <td>0.182815</td>\n",
       "      <td>-0.3125</td>\n",
       "      <td>0.65625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     U-val       tail     p-val     RBC     CLES\n",
       "MWU   94.5  two-sided  0.182815 -0.3125  0.65625"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg.mwu(q18_scores_real,q18_scores_placebo, tail='two-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Competence\n",
      "[28.25, 25.25, 25.76923076923077]\n",
      "[30.5, 26.0, 27]\n",
      "[24.931818181818183, 24.022727272727273, 20.358974358974358]\n",
      "Benevolence\n",
      "[18, 16.416666666666668, 16.384615384615383]\n",
      "[18.0, 17.0, 16]\n",
      "[2.727272727272727, 7.174242424242424, 3.7564102564102564]\n",
      "Integrity\n",
      "[18.333333333333332, 16.166666666666668, 17.846153846153847]\n",
      "[19.0, 17.0, 18]\n",
      "[4.606060606060606, 10.515151515151516, 4.4743589743589745]\n",
      "Intention to return\n",
      "[11.416666666666666, 10.5, 10.538461538461538]\n",
      "[12.0, 11.5, 10]\n",
      "[2.628787878787879, 4.818181818181818, 3.6025641025641026]\n",
      "Perceived Transparency\n",
      "[5.416666666666667, 4.25, 3.3846153846153846]\n",
      "[5.5, 4.5, 3]\n",
      "[2.628787878787879, 1.6590909090909092, 1.4230769230769231]\n",
      "Trusting Beliefs\n",
      "[17.761111111111113, 15.911111111111111, 16.564102564102562]\n",
      "[18.366666666666667, 16.833333333333332, 16.400000000000002]\n",
      "[4.0141077441077435, 7.425723905723906, 3.4249002849002856]\n",
      "Explicit Trust\n",
      "[5.916666666666667, 5.083333333333333, 5.3076923076923075]\n",
      "[6.0, 6.0, 6]\n",
      "[1.3560606060606062, 2.265151515151515, 2.064102564102564]\n",
      "MD Trust\n",
      "[17.04537037037037, 14.803703703703704, 14.175213675213675]\n",
      "[17.511111111111113, 15.333333333333334, 14.355555555555554]\n",
      "[6.709774597830154, 4.724070332959222, 1.9579661285216834]\n",
      "Q16\n",
      "[2.9166666666666665, 2.5833333333333335, 2.4615384615384617]\n",
      "[2.5, 2.0, 2]\n",
      "Q17\n",
      "[4, 4.583333333333333, 4.153846153846154]\n",
      "[4.0, 5.0, 4]\n",
      "Q18\n",
      "[2.9166666666666665, 2.1666666666666665, 2.4615384615384617]\n",
      "[2.5, 2.0, 2]\n",
      "Q19\n",
      "[5.083333333333333, 4.833333333333333, 5.538461538461538]\n",
      "[5.0, 5.0, 6]\n",
      "Q16 All Round\n",
      "2.6486486486486487\n",
      "2\n",
      "Q17 All Round\n",
      "4.243243243243243\n",
      "4\n",
      "Q18 All Round\n",
      "2.5135135135135136\n",
      "2\n",
      "Q19 All Round\n",
      "5.162162162162162\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "competence_averages = [statistics.mean(competence_scores[i]) for i in range(len(competence_scores))]\n",
    "competence_median = [statistics.median(competence_scores[i]) for i in range(len(competence_scores))]\n",
    "competence_variance = [statistics.variance(competence_scores[i]) for i in range(len(competence_scores))]\n",
    "\n",
    "\n",
    "benevolence_averages = [statistics.mean(benevolence_scores[i]) for i in range(len(benevolence_scores))]\n",
    "benevolence_median = [statistics.median(benevolence_scores[i]) for i in range(len(benevolence_scores))]\n",
    "benevolence_variance = [statistics.variance(benevolence_scores[i]) for i in range(len(benevolence_scores))]\n",
    "\n",
    "\n",
    "integrity_averages = [statistics.mean(integrity_scores[i]) for i in range(len(integrity_scores))]\n",
    "integrity_median = [statistics.median(integrity_scores[i]) for i in range(len(integrity_scores))]\n",
    "integrity_variance = [statistics.variance(integrity_scores[i]) for i in range(len(integrity_scores))]\n",
    "\n",
    "\n",
    "itr_averages = [statistics.mean(itr_scores[i]) for i in range(len(itr_scores))]\n",
    "itr_median = [statistics.median(itr_scores[i]) for i in range(len(itr_scores))]\n",
    "itr_variance = [statistics.variance(itr_scores[i]) for i in range(len(itr_scores))]\n",
    "\n",
    "\n",
    "pt_averages = [statistics.mean(pt_scores[i]) for i in range(len(pt_scores))]\n",
    "pt_median = [statistics.median(pt_scores[i]) for i in range(len(pt_scores))]\n",
    "pt_variance = [statistics.variance(pt_scores[i]) for i in range(len(pt_scores))]\n",
    "\n",
    "\n",
    "\n",
    "tb_averages = [statistics.mean(trusting_beliefs_scores[i]) for i in range(len(trusting_beliefs_scores))]\n",
    "tb_median = [statistics.median(trusting_beliefs_scores[i]) for i in range(len(trusting_beliefs_scores))]\n",
    "tb_variance = [statistics.variance(trusting_beliefs_scores[i]) for i in range(len(trusting_beliefs_scores))]\n",
    "\n",
    "\n",
    "et_averages = [statistics.mean(explicit_trust_scores[i]) for i in range(len(explicit_trust_scores))]\n",
    "et_median = [statistics.median(explicit_trust_scores[i]) for i in range(len(explicit_trust_scores))]\n",
    "et_variance = [statistics.variance(explicit_trust_scores[i]) for i in range(len(explicit_trust_scores))]\n",
    "\n",
    "\n",
    "ts_averages = [statistics.mean(md_trust_scores[i]) for i in range(len(md_trust_scores))]\n",
    "ts_median = [statistics.median(md_trust_scores[i]) for i in range(len(md_trust_scores))]\n",
    "ts_variance = [statistics.variance(md_trust_scores[i]) for i in range(len(md_trust_scores))]\n",
    "\n",
    "\n",
    "q16_averages = [statistics.mean(q16_scores[i]) for i in range(len(competence_scores))]\n",
    "q16_median = [statistics.median(q16_scores[i]) for i in range(len(competence_scores))]\n",
    "\n",
    "q17_averages = [statistics.mean(q17_scores[i]) for i in range(len(competence_scores))]\n",
    "q17_median = [statistics.median(q17_scores[i]) for i in range(len(competence_scores))]\n",
    "\n",
    "q18_averages = [statistics.mean(q18_scores[i]) for i in range(len(competence_scores))]\n",
    "q18_median = [statistics.median(q18_scores[i]) for i in range(len(competence_scores))]\n",
    "\n",
    "q19_averages = [statistics.mean(q19_scores[i]) for i in range(len(competence_scores))]\n",
    "q19_median = [statistics.median(q19_scores[i]) for i in range(len(competence_scores))]\n",
    "\n",
    "\n",
    "q16_averages_all_round = statistics.mean(q16_scores[0]+q16_scores[1]+q16_scores[2])\n",
    "q16_median_all_round = statistics.median(q16_scores[0]+q16_scores[1]+q16_scores[2])\n",
    "\n",
    "q17_averages_all_round = statistics.mean(q17_scores[0]+q17_scores[1]+q17_scores[2])\n",
    "q17_median_all_round = statistics.median(q17_scores[0]+q17_scores[1]+q17_scores[2])\n",
    "\n",
    "q18_averages_all_round = statistics.mean(q18_scores[0]+q18_scores[1]+q18_scores[2])\n",
    "q18_median_all_round = statistics.median(q18_scores[0]+q18_scores[1]+q18_scores[2])\n",
    "\n",
    "q19_averages_all_round = statistics.mean(q19_scores[0]+q19_scores[1]+q19_scores[2])\n",
    "q19_median_all_round = statistics.median(q19_scores[0]+q19_scores[1]+q19_scores[2])\n",
    "\n",
    "print(\"Competence\")\n",
    "print(competence_averages)\n",
    "print(competence_median)                                                                        \n",
    "print(competence_variance) \n",
    "print(\"Benevolence\")\n",
    "print(benevolence_averages)\n",
    "print(benevolence_median)                                                                            \n",
    "print(benevolence_variance)                                                                            \n",
    "\n",
    "  \n",
    "print(\"Integrity\")    \n",
    "print(integrity_averages)\n",
    "print(integrity_median)\n",
    "print(integrity_variance)\n",
    "\n",
    "                                                                          \n",
    "                                                                        \n",
    "print(\"Intention to return\")\n",
    "print(itr_averages)\n",
    "print(itr_median)\n",
    "print(itr_variance)\n",
    "print(\"Perceived Transparency\")\n",
    "print(pt_averages)\n",
    "print(pt_median)\n",
    "print(pt_variance)\n",
    "print(\"Trusting Beliefs\")\n",
    "print(tb_averages)\n",
    "print(tb_median)                                                                          \n",
    "print(tb_variance) \n",
    "\n",
    "print(\"Explicit Trust\")\n",
    "print(et_averages)\n",
    "print(et_median)\n",
    "print(et_variance)\n",
    "\n",
    "print(\"MD Trust\")\n",
    "print(ts_averages)\n",
    "print(ts_median)                                                                          \n",
    "print(ts_variance) \n",
    "\n",
    "print(\"Q16\")\n",
    "print(q16_averages)\n",
    "print(q16_median)                                                                          \n",
    "    \n",
    "print(\"Q17\")\n",
    "print(q17_averages)\n",
    "print(q17_median)                                                                          \n",
    "    \n",
    "print(\"Q18\")\n",
    "print(q18_averages)\n",
    "print(q18_median)                                                                          \n",
    "    \n",
    "print(\"Q19\")\n",
    "print(q19_averages)\n",
    "print(q19_median)                                                                          \n",
    "    \n",
    "print(\"Q16 All Round\")\n",
    "print(q16_averages_all_round)\n",
    "print(q16_median_all_round)  \n",
    "\n",
    "print(\"Q17 All Round\")\n",
    "print(q17_averages_all_round)\n",
    "print(q17_median_all_round)  \n",
    "    \n",
    "print(\"Q18 All Round\")\n",
    "print(q18_averages_all_round)\n",
    "print(q18_median_all_round) \n",
    "\n",
    "print(\"Q19 All Round\")\n",
    "print(q19_averages_all_round)\n",
    "print(q19_median_all_round)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
